[1,0]<stderr>:  0%|          | 0/500 [00:00<?, ?it/s][1,0]<stderr>: 37%|‚ñà‚ñà‚ñà‚ñã      | 187/500 [00:00<00:00, 1862.89it/s][1,0]<stderr>: 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 374/500 [00:00<00:00, 1842.51it/s][1,0]<stderr>:100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:00<00:00, 1807.19it/s][1,0]<stderr>:
[1,0]<stderr>:Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']
[1,0]<stderr>:You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[1,0]<stderr>:/nobackup/users/gtangg12/anaconda3/envs/task_planning_babyai/lib/python3.8/site-packages/torch/utils/tensorboard/__init__.py:6: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
[1,0]<stderr>:  if not hasattr(tensorboard, '__version__') or LooseVersion(tensorboard.__version__) < LooseVersion('1.15'):
[1,0]<stderr>:***** Running training *****
[1,0]<stderr>:  Num examples = 425
[1,0]<stderr>:  Num Epochs = 5
[1,0]<stderr>:  Instantaneous batch size per device = 4
[1,0]<stderr>:  Total train batch size (w. parallel, distributed & accumulation) = 32
[1,0]<stderr>:  Gradient Accumulation steps = 4
[1,0]<stderr>:  Total optimization steps = 65
[1,0]<stderr>:  0%|          | 0/65 [00:00<?, ?it/s][1,0]<stderr>:/nobackup/users/gtangg12/anaconda3/envs/task_planning_babyai/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
[1,0]<stderr>:  warnings.warn('Was asked to gather along dimension 0, but all '
[1,0]<stderr>:/nobackup/users/gtangg12/anaconda3/envs/task_planning_babyai/lib/python3.8/site-packages/torch/cuda/nccl.py:47: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working
[1,0]<stderr>:  if not isinstance(inputs, collections.Container) or isinstance(inputs, torch.Tensor):
[1,0]<stderr>:  2%|‚ñè         | 1/65 [00:05<06:01,  5.64s/it][1,0]<stderr>:  3%|‚ñé         | 2/65 [00:07<03:26,  3.28s/it][1,0]<stderr>:  5%|‚ñç         | 3/65 [00:08<02:35,  2.52s/it][1,0]<stderr>:  6%|‚ñå         | 4/65 [00:10<02:11,  2.16s/it][1,0]<stderr>:  8%|‚ñä         | 5/65 [00:12<01:57,  1.96s/it][1,0]<stderr>:  9%|‚ñâ         | 6/65 [00:13<01:48,  1.84s/it][1,0]<stderr>: 11%|‚ñà         | 7/65 [00:15<01:42,  1.77s/it][1,0]<stderr>: 12%|‚ñà‚ñè        | 8/65 [00:16<01:37,  1.72s/it][1,0]<stderr>: 14%|‚ñà‚ñç        | 9/65 [00:18<01:34,  1.69s/it][1,0]<stderr>: 15%|‚ñà‚ñå        | 10/65 [00:20<01:31,  1.66s/it][1,0]<stderr>: 17%|‚ñà‚ñã        | 11/65 [00:21<01:29,  1.66s/it][1,0]<stderr>: 18%|‚ñà‚ñä        | 12/65 [00:23<01:27,  1.65s/it][1,0]<stderr>: 20%|‚ñà‚ñà        | 13/65 [00:25<01:25,  1.64s/it][1,0]<stderr>:                                               [1,0]<stderr>: 20%|‚ñà‚ñà        | 13/65 [00:25<01:25,  1.64s/it][1,0]<stderr>:***** Running Evaluation *****
[1,0]<stderr>:  Num examples = 75
[1,0]<stderr>:  Batch size = 8
[1,0]<stderr>:
[1,0]<stderr>:  0%|          | 0/10 [00:00<?, ?it/s][1,0]<stderr>:[A[1,0]<stderr>:
[1,0]<stderr>: 20%|‚ñà‚ñà        | 2/10 [00:00<00:00, 13.03it/s][1,0]<stderr>:[A[1,0]<stderr>:
[1,0]<stderr>: 40%|‚ñà‚ñà‚ñà‚ñà      | 4/10 [00:00<00:00,  8.16it/s][1,0]<stderr>:[A[1,0]<stderr>:
[1,0]<stderr>: 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 5/10 [00:00<00:00,  7.61it/s][1,0]<stderr>:[A[1,0]<stderr>:
[1,0]<stderr>: 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 6/10 [00:00<00:00,  7.26it/s][1,0]<stderr>:[A[1,0]<stderr>:
[1,0]<stderr>: 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 7/10 [00:00<00:00,  7.02it/s][1,0]<stderr>:[A[1,0]<stderr>:
[1,0]<stderr>: 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 8/10 [00:01<00:00,  6.86it/s][1,0]<stderr>:[A[1,0]<stderr>:
[1,0]<stderr>: 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 9/10 [00:01<00:00,  6.76it/s][1,0]<stderr>:[A[1,0]<stderr>:Trainer is attempting to log a value of "{0: 0, 1: 0, 2: 75}" of type <class 'dict'> for key "eval/preds_freq" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
[1,0]<stderr>:Trainer is attempting to log a value of "{0: 15, 1: 11, 2: 45, 3: 1, 4: 0, 5: 3}" of type <class 'dict'> for key "eval/labels_freq" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
[1,0]<stderr>:                                               [1,0]<stderr>:[1,0]<stderr>:
[1,0]<stderr>:                                              [1,0]<stderr>:[A[1,0]<stderr>: 20%|‚ñà‚ñà        | 13/65 [00:27<01:25,  1.64s/it][1,0]<stderr>:
[1,0]<stderr>:100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  6.76it/s][1,0]<stderr>:[A[1,0]<stderr>:
[1,0]<stderr>:                                               [A[1,0]<stderr>:Saving model checkpoint to /nobackup/users/gtangg12/task_planning_bayes_factor/checkpoints/babyai_gpt2_finetune_num_data/n500/checkpoint-13
[1,0]<stderr>:Configuration saved in /nobackup/users/gtangg12/task_planning_bayes_factor/checkpoints/babyai_gpt2_finetune_num_data/n500/checkpoint-13/config.json
[1,0]<stderr>:Model weights saved in /nobackup/users/gtangg12/task_planning_bayes_factor/checkpoints/babyai_gpt2_finetune_num_data/n500/checkpoint-13/pytorch_model.bin
[1,0]<stderr>:/nobackup/users/gtangg12/anaconda3/envs/task_planning_babyai/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
[1,0]<stderr>:  warnings.warn('Was asked to gather along dimension 0, but all '
[1,0]<stderr>: 22%|‚ñà‚ñà‚ñè       | 14/65 [00:30<02:25,  2.85s/it][1,0]<stderr>: 23%|‚ñà‚ñà‚ñé       | 15/65 [00:32<02:03,  2.48s/it][1,0]<stderr>: 25%|‚ñà‚ñà‚ñç       | 16/65 [00:33<01:48,  2.22s/it][1,0]<stderr>: 26%|‚ñà‚ñà‚ñå       | 17/65 [00:35<01:38,  2.04s/it][1,0]<stderr>: 28%|‚ñà‚ñà‚ñä       | 18/65 [00:37<01:30,  1.92s/it][1,0]<stderr>: 29%|‚ñà‚ñà‚ñâ       | 19/65 [00:38<01:24,  1.84s/it][1,0]<stderr>: 31%|‚ñà‚ñà‚ñà       | 20/65 [00:40<01:20,  1.78s/it][1,0]<stderr>: 32%|‚ñà‚ñà‚ñà‚ñè      | 21/65 [00:42<01:16,  1.74s/it][1,0]<stderr>: 34%|‚ñà‚ñà‚ñà‚ñç      | 22/65 [00:43<01:13,  1.71s/it][1,0]<stderr>: 35%|‚ñà‚ñà‚ñà‚ñå      | 23/65 [00:45<01:11,  1.69s/it][1,0]<stderr>: 37%|‚ñà‚ñà‚ñà‚ñã      | 24/65 [00:47<01:09,  1.69s/it][1,0]<stderr>: 38%|‚ñà‚ñà‚ñà‚ñä      | 25/65 [00:48<01:07,  1.68s/it][1,0]<stderr>: 40%|‚ñà‚ñà‚ñà‚ñà      | 26/65 [00:50<01:05,  1.67s/it][1,0]<stderr>:                                               [1,0]<stderr>:[1,0]<stderr>: 40%|‚ñà‚ñà‚ñà‚ñà      | 26/65 [00:50<01:05,  1.67s/it][1,0]<stderr>:***** Running Evaluation *****
[1,0]<stderr>:  Num examples = 75
[1,0]<stderr>:  Batch size = 8
[1,0]<stderr>:
[1,0]<stderr>:  0%|          | 0/10 [00:00<?, ?it/s][1,0]<stderr>:[A[1,0]<stderr>:
[1,0]<stderr>: 20%|‚ñà‚ñà        | 2/10 [00:00<00:00, 12.95it/s][1,0]<stderr>:[A[1,0]<stderr>:
[1,0]<stderr>: 40%|‚ñà‚ñà‚ñà‚ñà      | 4/10 [00:00<00:00,  8.10it/s][1,0]<stderr>:[A[1,0]<stderr>:
[1,0]<stderr>: 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 5/10 [00:00<00:00,  6.98it/s][1,0]<stderr>:[A[1,0]<stderr>:
[1,0]<stderr>: 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 6/10 [00:00<00:00,  6.42it/s][1,0]<stderr>:[A[1,0]<stderr>:
[1,0]<stderr>: 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 7/10 [00:01<00:00,  6.08it/s][1,0]<stderr>:[A[1,0]<stderr>:
[1,0]<stderr>: 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 8/10 [00:01<00:00,  5.92it/s][1,0]<stderr>:[A[1,0]<stderr>:
[1,0]<stderr>: 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 9/10 [00:01<00:00,  5.81it/s][1,0]<stderr>:[A[1,0]<stderr>:Trainer is attempting to log a value of "{0: 0, 1: 0, 2: 75}" of type <class 'dict'> for key "eval/preds_freq" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
[1,0]<stderr>:Trainer is attempting to log a value of "{0: 15, 1: 11, 2: 45, 3: 1, 4: 0, 5: 3}" of type <class 'dict'> for key "eval/labels_freq" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
[1,0]<stderr>:                                               [1,0]<stderr>:[1,0]<stderr>:
[1,0]<stderr>:                                              [1,0]<stderr>:[A[1,0]<stderr>: 40%|‚ñà‚ñà‚ñà‚ñà      | 26/65 [00:52<01:05,  1.67s/it][1,0]<stderr>:
[1,0]<stderr>:100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  5.81it/s][1,0]<stderr>:[A[1,0]<stderr>:
[1,0]<stderr>:                                               [A[1,0]<stderr>:Saving model checkpoint to /nobackup/users/gtangg12/task_planning_bayes_factor/checkpoints/babyai_gpt2_finetune_num_data/n500/checkpoint-26
[1,0]<stderr>:Configuration saved in /nobackup/users/gtangg12/task_planning_bayes_factor/checkpoints/babyai_gpt2_finetune_num_data/n500/checkpoint-26/config.json
[1,0]<stderr>:Model weights saved in /nobackup/users/gtangg12/task_planning_bayes_factor/checkpoints/babyai_gpt2_finetune_num_data/n500/checkpoint-26/pytorch_model.bin
[1,0]<stderr>:/nobackup/users/gtangg12/anaconda3/envs/task_planning_babyai/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
[1,0]<stderr>:  warnings.warn('Was asked to gather along dimension 0, but all '
[1,0]<stderr>: 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 27/65 [00:56<01:49,  2.88s/it][1,0]<stderr>: 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 28/65 [00:57<01:33,  2.52s/it][1,0]<stderr>: 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 29/65 [00:59<01:20,  2.25s/it][1,0]<stderr>: 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 30/65 [01:01<01:12,  2.06s/it][1,0]<stderr>: 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 31/65 [01:02<01:05,  1.93s/it][1,0]<stderr>: 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 32/65 [01:04<01:00,  1.83s/it][1,0]<stderr>: 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 33/65 [01:05<00:56,  1.77s/it][1,0]<stderr>: 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 34/65 [01:07<00:53,  1.72s/it][1,0]<stderr>: 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 35/65 [01:09<00:50,  1.70s/it][1,0]<stderr>: 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 36/65 [01:10<00:48,  1.68s/it][1,0]<stderr>: 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 37/65 [01:12<00:46,  1.66s/it][1,0]<stderr>: 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 38/65 [01:14<00:44,  1.65s/it][1,0]<stderr>: 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 39/65 [01:15<00:42,  1.64s/it][1,0]<stderr>:                                               [1,0]<stderr>:[1,0]<stderr>: 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 39/65 [01:16<00:42,  1.64s/it][1,0]<stderr>:***** Running Evaluation *****
[1,0]<stderr>:  Num examples = 75
[1,0]<stderr>:  Batch size = 8
[1,0]<stderr>:
[1,0]<stderr>:  0%|          | 0/10 [00:00<?, ?it/s][1,0]<stderr>:[A[1,0]<stderr>:
[1,0]<stderr>: 20%|‚ñà‚ñà        | 2/10 [00:00<00:00, 10.46it/s][1,0]<stderr>:[A[1,0]<stderr>:
[1,0]<stderr>: 40%|‚ñà‚ñà‚ñà‚ñà      | 4/10 [00:00<00:00,  7.70it/s][1,0]<stderr>:[A[1,0]<stderr>:
[1,0]<stderr>: 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 5/10 [00:00<00:00,  7.31it/s][1,0]<stderr>:[A[1,0]<stderr>:
[1,0]<stderr>: 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 6/10 [00:00<00:00,  6.99it/s][1,0]<stderr>:[A[1,0]<stderr>:
[1,0]<stderr>: 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 7/10 [00:00<00:00,  6.83it/s][1,0]<stderr>:[A[1,0]<stderr>:
[1,0]<stderr>: 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 8/10 [00:01<00:00,  6.71it/s][1,0]<stderr>:[A[1,0]<stderr>:
[1,0]<stderr>: 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 9/10 [00:01<00:00,  6.57it/s][1,0]<stderr>:[A[1,0]<stderr>:Trainer is attempting to log a value of "{0: 0, 1: 0, 2: 75}" of type <class 'dict'> for key "eval/preds_freq" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
[1,0]<stderr>:Trainer is attempting to log a value of "{0: 15, 1: 11, 2: 45, 3: 1, 4: 0, 5: 3}" of type <class 'dict'> for key "eval/labels_freq" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
[1,0]<stderr>:                                               [1,0]<stderr>:[1,0]<stderr>:
[1,0]<stderr>:                                              [1,0]<stderr>:[A[1,0]<stderr>: 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 39/65 [01:17<00:42,  1.64s/it][1,0]<stderr>:
[1,0]<stderr>:100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  6.57it/s][1,0]<stderr>:[A[1,0]<stderr>:
[1,0]<stderr>:                                               [A[1,0]<stderr>:Saving model checkpoint to /nobackup/users/gtangg12/task_planning_bayes_factor/checkpoints/babyai_gpt2_finetune_num_data/n500/checkpoint-39
[1,0]<stderr>:Configuration saved in /nobackup/users/gtangg12/task_planning_bayes_factor/checkpoints/babyai_gpt2_finetune_num_data/n500/checkpoint-39/config.json
[1,0]<stderr>:Model weights saved in /nobackup/users/gtangg12/task_planning_bayes_factor/checkpoints/babyai_gpt2_finetune_num_data/n500/checkpoint-39/pytorch_model.bin
[1,0]<stderr>:/nobackup/users/gtangg12/anaconda3/envs/task_planning_babyai/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
[1,0]<stderr>:  warnings.warn('Was asked to gather along dimension 0, but all '
[1,0]<stderr>: 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 40/65 [01:21<01:11,  2.86s/it][1,0]<stderr>: 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 41/65 [01:22<00:59,  2.49s/it][1,0]<stderr>: 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 42/65 [01:24<00:51,  2.22s/it][1,0]<stderr>: 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 43/65 [01:26<00:44,  2.04s/it][1,0]<stderr>: 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 44/65 [01:27<00:40,  1.92s/it][1,0]<stderr>: 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 45/65 [01:29<00:36,  1.83s/it][1,0]<stderr>: 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 46/65 [01:31<00:33,  1.76s/it][1,0]<stderr>: 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 47/65 [01:32<00:30,  1.72s/it][1,0]<stderr>: 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 48/65 [01:34<00:28,  1.69s/it][1,0]<stderr>: 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 49/65 [01:35<00:26,  1.67s/it][1,0]<stderr>: 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 50/65 [01:37<00:24,  1.66s/it][1,0]<stderr>: 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 51/65 [01:39<00:23,  1.65s/it][1,0]<stderr>: 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 52/65 [01:40<00:21,  1.64s/it][1,0]<stderr>:                                               [1,0]<stderr>:[1,0]<stderr>: 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 52/65 [01:41<00:21,  1.64s/it][1,0]<stderr>:***** Running Evaluation *****
[1,0]<stderr>:  Num examples = 75
[1,0]<stderr>:  Batch size = 8
[1,0]<stderr>:
[1,0]<stderr>:  0%|          | 0/10 [00:00<?, ?it/s][1,0]<stderr>:[A[1,0]<stderr>:
[1,0]<stderr>: 20%|‚ñà‚ñà        | 2/10 [00:00<00:00, 12.94it/s][1,0]<stderr>:[A[1,0]<stderr>:
[1,0]<stderr>: 40%|‚ñà‚ñà‚ñà‚ñà      | 4/10 [00:00<00:00,  8.18it/s][1,0]<stderr>:[A[1,0]<stderr>:
[1,0]<stderr>: 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 5/10 [00:00<00:00,  7.61it/s][1,0]<stderr>:[A[1,0]<stderr>:
[1,0]<stderr>: 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 6/10 [00:00<00:00,  7.25it/s][1,0]<stderr>:[A[1,0]<stderr>:
[1,0]<stderr>: 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 7/10 [00:00<00:00,  7.02it/s][1,0]<stderr>:[A[1,0]<stderr>:
[1,0]<stderr>: 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 8/10 [00:01<00:00,  6.86it/s][1,0]<stderr>:[A[1,0]<stderr>:
[1,0]<stderr>: 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 9/10 [00:01<00:00,  6.76it/s][1,0]<stderr>:[A[1,0]<stderr>:Trainer is attempting to log a value of "{0: 0, 1: 0, 2: 75}" of type <class 'dict'> for key "eval/preds_freq" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
[1,0]<stderr>:Trainer is attempting to log a value of "{0: 15, 1: 11, 2: 45, 3: 1, 4: 0, 5: 3}" of type <class 'dict'> for key "eval/labels_freq" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
[1,0]<stderr>:                                               [1,0]<stderr>:[1,0]<stderr>:
[1,0]<stderr>:                                              [1,0]<stderr>:[A[1,0]<stderr>: 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 52/65 [01:42<00:21,  1.64s/it][1,0]<stderr>:
[1,0]<stderr>:100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  6.76it/s][1,0]<stderr>:[A[1,0]<stderr>:
[1,0]<stderr>:                                               [A[1,0]<stderr>:Saving model checkpoint to /nobackup/users/gtangg12/task_planning_bayes_factor/checkpoints/babyai_gpt2_finetune_num_data/n500/checkpoint-52
[1,0]<stderr>:Configuration saved in /nobackup/users/gtangg12/task_planning_bayes_factor/checkpoints/babyai_gpt2_finetune_num_data/n500/checkpoint-52/config.json
[1,0]<stderr>:Model weights saved in /nobackup/users/gtangg12/task_planning_bayes_factor/checkpoints/babyai_gpt2_finetune_num_data/n500/checkpoint-52/pytorch_model.bin
[1,0]<stderr>:/nobackup/users/gtangg12/anaconda3/envs/task_planning_babyai/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
[1,0]<stderr>:  warnings.warn('Was asked to gather along dimension 0, but all '
[1,0]<stderr>: 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 53/65 [01:46<00:33,  2.76s/it][1,0]<stderr>: 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 54/65 [01:47<00:26,  2.41s/it][1,0]<stderr>: 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 55/65 [01:49<00:21,  2.17s/it][1,0]<stderr>: 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 56/65 [01:50<00:18,  2.01s/it][1,0]<stderr>: 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 57/65 [01:52<00:15,  1.89s/it][1,0]<stderr>: 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 58/65 [01:54<00:12,  1.81s/it][1,0]<stderr>: 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 59/65 [01:55<00:10,  1.75s/it][1,0]<stderr>: 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 60/65 [01:57<00:08,  1.71s/it][1,0]<stderr>: 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 61/65 [01:59<00:06,  1.68s/it][1,0]<stderr>: 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 62/65 [02:00<00:05,  1.68s/it][1,0]<stderr>: 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 63/65 [02:02<00:03,  1.66s/it][1,0]<stderr>: 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 64/65 [02:03<00:01,  1.65s/it][1,0]<stderr>:100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 65/65 [02:05<00:00,  1.64s/it][1,0]<stderr>:                                               [1,0]<stderr>:[1,0]<stderr>:100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 65/65 [02:05<00:00,  1.64s/it][1,0]<stderr>:***** Running Evaluation *****
[1,0]<stderr>:  Num examples = 75
[1,0]<stderr>:  Batch size = 8
[1,0]<stderr>:
[1,0]<stderr>:  0%|          | 0/10 [00:00<?, ?it/s][1,0]<stderr>:[A[1,0]<stderr>:
[1,0]<stderr>: 20%|‚ñà‚ñà        | 2/10 [00:00<00:00, 12.98it/s][1,0]<stderr>:[A[1,0]<stderr>:
[1,0]<stderr>: 40%|‚ñà‚ñà‚ñà‚ñà      | 4/10 [00:00<00:00,  8.19it/s][1,0]<stderr>:[A[1,0]<stderr>:
[1,0]<stderr>: 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 5/10 [00:00<00:00,  7.61it/s][1,0]<stderr>:[A[1,0]<stderr>:
[1,0]<stderr>: 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 6/10 [00:00<00:00,  7.24it/s][1,0]<stderr>:[A[1,0]<stderr>:
[1,0]<stderr>: 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 7/10 [00:00<00:00,  6.99it/s][1,0]<stderr>:[A[1,0]<stderr>:
[1,0]<stderr>: 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 8/10 [00:01<00:00,  6.83it/s][1,0]<stderr>:[A[1,0]<stderr>:
[1,0]<stderr>: 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 9/10 [00:01<00:00,  6.72it/s][1,0]<stderr>:[A[1,0]<stderr>:Trainer is attempting to log a value of "{0: 0, 1: 0, 2: 75}" of type <class 'dict'> for key "eval/preds_freq" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
[1,0]<stderr>:Trainer is attempting to log a value of "{0: 15, 1: 11, 2: 45, 3: 1, 4: 0, 5: 3}" of type <class 'dict'> for key "eval/labels_freq" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
[1,0]<stderr>:                                               [1,0]<stderr>:[1,0]<stderr>:
[1,0]<stderr>:                                              [1,0]<stderr>:[A[1,0]<stderr>:100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 65/65 [02:07<00:00,  1.64s/it][1,0]<stderr>:
[1,0]<stderr>:100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  6.72it/s][1,0]<stderr>:[A[1,0]<stderr>:
[1,0]<stderr>:                                               [A[1,0]<stderr>:Saving model checkpoint to /nobackup/users/gtangg12/task_planning_bayes_factor/checkpoints/babyai_gpt2_finetune_num_data/n500/checkpoint-65
[1,0]<stderr>:Configuration saved in /nobackup/users/gtangg12/task_planning_bayes_factor/checkpoints/babyai_gpt2_finetune_num_data/n500/checkpoint-65/config.json
[1,0]<stderr>:Model weights saved in /nobackup/users/gtangg12/task_planning_bayes_factor/checkpoints/babyai_gpt2_finetune_num_data/n500/checkpoint-65/pytorch_model.bin
[1,0]<stderr>:
[1,0]<stderr>:
[1,0]<stderr>:Training completed. Do not forget to share your model on huggingface.co/models =)
[1,0]<stderr>:
[1,0]<stderr>:
[1,0]<stderr>:                                               [1,0]<stderr>:[1,0]<stderr>:100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 65/65 [02:08<00:00,  1.64s/it][1,0]<stderr>:100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 65/65 [02:08<00:00,  1.98s/it][1,0]<stderr>:
